INFO 07-04 09:32:56 [__init__.py:244] Automatically detected platform cuda.
INFO 07-04 09:33:02 [api_server.py:1287] vLLM API server version 0.9.1
INFO 07-04 09:33:02 [cli_args.py:309] non-default args: {'host': 'localhost', 'port': 64776, 'model': 'Unbabel/Tower-Plus-72B', 'trust_remote_code': True, 'max_model_len': 32768, 'tensor_parallel_size': 4, 'disable_log_requests': True}
INFO 07-04 09:33:18 [config.py:823] This model supports multiple tasks: {'score', 'generate', 'classify', 'embed', 'reward'}. Defaulting to 'generate'.
INFO 07-04 09:33:18 [config.py:1946] Defaulting to use mp for distributed inference
INFO 07-04 09:33:18 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=2048.
WARNING 07-04 09:33:21 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
INFO 07-04 09:33:27 [__init__.py:244] Automatically detected platform cuda.
INFO 07-04 09:33:31 [core.py:455] Waiting for init message from front-end.
INFO 07-04 09:33:31 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='Unbabel/Tower-Plus-72B', speculative_config=None, tokenizer='Unbabel/Tower-Plus-72B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Unbabel/Tower-Plus-72B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":512,"local_cache_dir":null}
WARNING 07-04 09:33:31 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 32 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 07-04 09:33:31 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_cad2950d'), local_subscribe_addr='ipc:///tmp/94e968ce-adc6-4f8c-9681-c409aeeaf0cb', remote_subscribe_addr=None, remote_addr_ipv6=False)
WARNING 07-04 09:33:33 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
WARNING 07-04 09:33:33 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
WARNING 07-04 09:33:33 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
WARNING 07-04 09:33:33 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
INFO 07-04 09:33:40 [__init__.py:244] Automatically detected platform cuda.
INFO 07-04 09:33:40 [__init__.py:244] Automatically detected platform cuda.
INFO 07-04 09:33:40 [__init__.py:244] Automatically detected platform cuda.
INFO 07-04 09:33:40 [__init__.py:244] Automatically detected platform cuda.
WARNING 07-04 09:33:46 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1516dede6240>
WARNING 07-04 09:33:46 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x14d9ed401f10>
WARNING 07-04 09:33:46 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x149644edf0b0>
WARNING 07-04 09:33:46 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x145bec1b2180>
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3f1db5f9'), local_subscribe_addr='ipc:///tmp/efb6be02-a9b4-417f-aac3-f2db61e394f6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d63bf384'), local_subscribe_addr='ipc:///tmp/0774895c-e4bc-4fd0-9df2-1cbc4633ff6d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_3047625c'), local_subscribe_addr='ipc:///tmp/488a29d3-f7bb-4249-95b5-9c58152162e4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_749fe5e6'), local_subscribe_addr='ipc:///tmp/af5fbc6a-adf8-4134-a405-b014c3e26c31', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:46 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:46 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:46 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:46 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:46 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:46 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:46 [utils.py:1126] Found nccl from library libnccl.so.2
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:46 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:47 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /leonardo/home/userexternal/midahl00/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /leonardo/home/userexternal/midahl00/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:47 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /leonardo/home/userexternal/midahl00/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:47 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /leonardo/home/userexternal/midahl00/.cache/vllm/gpu_p2p_access_cache_for_0,1,2,3.json
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_e26b1600'), local_subscribe_addr='ipc:///tmp/379b8622-a569-4716-b6a5-9367c06b7618', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [parallel_state.py:1065] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:47 [parallel_state.py:1065] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:47 [parallel_state.py:1065] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:47 [parallel_state.py:1065] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m WARNING 07-04 09:33:47 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m WARNING 07-04 09:33:47 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m WARNING 07-04 09:33:47 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m WARNING 07-04 09:33:47 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1595] Starting to load model Unbabel/Tower-Plus-72B...
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1595] Starting to load model Unbabel/Tower-Plus-72B...
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1595] Starting to load model Unbabel/Tower-Plus-72B...
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1595] Starting to load model Unbabel/Tower-Plus-72B...
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:47 [gpu_model_runner.py:1600] Loading model from scratch...
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:47 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:47 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:47 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:47 [cuda.py:252] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:33:48 [weight_utils.py:292] Using model weights format ['*.safetensors', '*.bin', '*.pt']
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:33:48 [weight_utils.py:292] Using model weights format ['*.safetensors', '*.bin', '*.pt']
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:33:48 [weight_utils.py:292] Using model weights format ['*.safetensors', '*.bin', '*.pt']
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:33:48 [weight_utils.py:292] Using model weights format ['*.safetensors', '*.bin', '*.pt']
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/31 [00:00<?, ?it/s]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:   3% Completed | 1/31 [00:11<05:52, 11.74s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:   6% Completed | 2/31 [00:19<04:33,  9.43s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  10% Completed | 3/31 [00:40<06:54, 14.81s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  13% Completed | 4/31 [01:00<07:34, 16.85s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  16% Completed | 5/31 [01:18<07:30, 17.31s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  19% Completed | 6/31 [01:39<07:44, 18.57s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  23% Completed | 7/31 [02:02<07:58, 19.94s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  26% Completed | 8/31 [02:23<07:44, 20.20s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  29% Completed | 9/31 [02:34<06:24, 17.47s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  32% Completed | 10/31 [02:59<06:51, 19.59s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  35% Completed | 11/31 [03:23<07:00, 21.03s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  39% Completed | 12/31 [04:02<08:25, 26.60s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  42% Completed | 13/31 [04:45<09:24, 31.37s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  45% Completed | 14/31 [04:58<07:21, 25.96s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  48% Completed | 15/31 [05:24<06:57, 26.07s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  52% Completed | 16/31 [05:47<06:14, 24.94s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  55% Completed | 17/31 [06:03<05:12, 22.31s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  58% Completed | 18/31 [06:50<06:24, 29.61s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  61% Completed | 19/31 [07:03<04:56, 24.71s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  65% Completed | 20/31 [07:10<03:35, 19.56s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  68% Completed | 21/31 [07:19<02:43, 16.32s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  71% Completed | 22/31 [07:29<02:08, 14.33s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  74% Completed | 23/31 [07:40<01:46, 13.31s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  77% Completed | 24/31 [07:50<01:25, 12.24s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  81% Completed | 25/31 [07:58<01:06, 11.05s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  84% Completed | 26/31 [08:09<00:55, 11.19s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  87% Completed | 27/31 [08:18<00:41, 10.37s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  90% Completed | 28/31 [08:29<00:31, 10.56s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  94% Completed | 29/31 [08:30<00:15,  7.69s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards:  97% Completed | 30/31 [08:39<00:08,  8.03s/it]
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:42:39 [default_loader.py:272] Loading weights took 531.53 seconds
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:42:39 [default_loader.py:272] Loading weights took 531.52 seconds
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards: 100% Completed | 31/31 [08:51<00:00,  9.34s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m Loading safetensors checkpoint shards: 100% Completed | 31/31 [08:51<00:00, 17.15s/it]
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m 
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:42:39 [default_loader.py:272] Loading weights took 531.51 seconds
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:42:39 [default_loader.py:272] Loading weights took 531.67 seconds
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:42:39 [gpu_model_runner.py:1624] Model loading took 33.9836 GiB and 532.155528 seconds
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:42:39 [gpu_model_runner.py:1624] Model loading took 33.9836 GiB and 532.144658 seconds
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:42:40 [gpu_model_runner.py:1624] Model loading took 33.9836 GiB and 532.189954 seconds
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:42:40 [gpu_model_runner.py:1624] Model loading took 33.9836 GiB and 532.245126 seconds
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:42:57 [backends.py:460] vLLM's torch.compile cache is disabled.
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:42:57 [backends.py:460] vLLM's torch.compile cache is disabled.
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:42:57 [backends.py:472] Dynamo bytecode transform time: 16.81 s
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:42:57 [backends.py:472] Dynamo bytecode transform time: 16.82 s
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:42:57 [backends.py:460] vLLM's torch.compile cache is disabled.
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:42:57 [backends.py:460] vLLM's torch.compile cache is disabled.
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:42:57 [backends.py:472] Dynamo bytecode transform time: 16.82 s
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:42:57 [backends.py:472] Dynamo bytecode transform time: 16.81 s
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:43:00 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:43:00 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:43:00 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:43:00 [backends.py:161] Cache the graph of shape None for later use
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:43:52 [backends.py:173] Compiling a graph for general shape takes 54.47 s
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:43:52 [backends.py:173] Compiling a graph for general shape takes 54.59 s
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:43:53 [backends.py:173] Compiling a graph for general shape takes 55.54 s
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:43:53 [backends.py:173] Compiling a graph for general shape takes 55.72 s
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:44:00 [monitor.py:34] torch.compile takes 71.29 s in total
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:44:00 [monitor.py:34] torch.compile takes 72.35 s in total
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:44:00 [monitor.py:34] torch.compile takes 71.40 s in total
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:44:00 [monitor.py:34] torch.compile takes 72.53 s in total
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:44:02 [gpu_worker.py:227] Available KV cache memory: 19.88 GiB
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:44:02 [gpu_worker.py:227] Available KV cache memory: 19.74 GiB
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:44:02 [gpu_worker.py:227] Available KV cache memory: 19.74 GiB
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:44:02 [gpu_worker.py:227] Available KV cache memory: 19.88 GiB
INFO 07-04 09:44:02 [kv_cache_utils.py:715] GPU KV cache size: 260,544 tokens
INFO 07-04 09:44:02 [kv_cache_utils.py:719] Maximum concurrency for 32,768 tokens per request: 7.95x
INFO 07-04 09:44:02 [kv_cache_utils.py:715] GPU KV cache size: 258,704 tokens
INFO 07-04 09:44:02 [kv_cache_utils.py:719] Maximum concurrency for 32,768 tokens per request: 7.90x
INFO 07-04 09:44:02 [kv_cache_utils.py:715] GPU KV cache size: 258,704 tokens
INFO 07-04 09:44:02 [kv_cache_utils.py:719] Maximum concurrency for 32,768 tokens per request: 7.90x
INFO 07-04 09:44:02 [kv_cache_utils.py:715] GPU KV cache size: 260,544 tokens
INFO 07-04 09:44:02 [kv_cache_utils.py:719] Maximum concurrency for 32,768 tokens per request: 7.95x
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:44:38 [custom_all_reduce.py:196] Registering 10626 cuda graph addresses
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:44:39 [custom_all_reduce.py:196] Registering 10626 cuda graph addresses
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:44:39 [custom_all_reduce.py:196] Registering 10626 cuda graph addresses
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:44:39 [custom_all_reduce.py:196] Registering 10626 cuda graph addresses
[1;36m(VllmWorker rank=3 pid=1466273)[0;0m INFO 07-04 09:44:39 [gpu_model_runner.py:2048] Graph capturing finished in 37 secs, took 4.40 GiB
[1;36m(VllmWorker rank=0 pid=1466270)[0;0m INFO 07-04 09:44:39 [gpu_model_runner.py:2048] Graph capturing finished in 37 secs, took 4.40 GiB
[1;36m(VllmWorker rank=1 pid=1466271)[0;0m INFO 07-04 09:44:39 [gpu_model_runner.py:2048] Graph capturing finished in 37 secs, took 4.40 GiB
[1;36m(VllmWorker rank=2 pid=1466272)[0;0m INFO 07-04 09:44:39 [gpu_model_runner.py:2048] Graph capturing finished in 37 secs, took 4.40 GiB
INFO 07-04 09:44:39 [core.py:171] init engine (profile, create kv cache, warmup model) took 119.68 seconds
INFO 07-04 09:44:40 [loggers.py:137] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 16169
INFO 07-04 09:44:40 [api_server.py:1349] Starting vLLM API server 0 on http://localhost:64776
INFO 07-04 09:44:40 [launcher.py:29] Available routes are:
INFO 07-04 09:44:40 [launcher.py:37] Route: /openapi.json, Methods: HEAD, GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /docs, Methods: HEAD, GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /docs/oauth2-redirect, Methods: HEAD, GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /redoc, Methods: HEAD, GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /health, Methods: GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /load, Methods: GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /ping, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /ping, Methods: GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /tokenize, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /detokenize, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/models, Methods: GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /version, Methods: GET
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/chat/completions, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/completions, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/embeddings, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /pooling, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /classify, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /score, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/score, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/audio/transcriptions, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /rerank, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v1/rerank, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /v2/rerank, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /invocations, Methods: POST
INFO 07-04 09:44:40 [launcher.py:37] Route: /metrics, Methods: GET
INFO:     Started server process [1466130]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     127.0.0.1:48508 - "GET /health HTTP/1.1" 200 OK
INFO 07-04 09:45:16 [chat_utils.py:420] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
INFO 07-04 09:45:20 [loggers.py:118] Engine 000: Avg prompt throughput: 2094.2 tokens/s, Avg generation throughput: 17.5 tokens/s, Running: 28 reqs, Waiting: 72 reqs, GPU KV cache usage: 8.3%, Prefix cache hit rate: 0.0%
INFO 07-04 09:45:30 [loggers.py:118] Engine 000: Avg prompt throughput: 5273.8 tokens/s, Avg generation throughput: 159.1 tokens/s, Running: 92 reqs, Waiting: 8 reqs, GPU KV cache usage: 29.8%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:34566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:45:40 [loggers.py:118] Engine 000: Avg prompt throughput: 986.7 tokens/s, Avg generation throughput: 1528.3 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 38.7%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:45:50 [loggers.py:118] Engine 000: Avg prompt throughput: 841.0 tokens/s, Avg generation throughput: 1408.5 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 44.6%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34206 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:00 [loggers.py:118] Engine 000: Avg prompt throughput: 887.8 tokens/s, Avg generation throughput: 1508.8 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 51.6%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:34136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34534 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:10 [loggers.py:118] Engine 000: Avg prompt throughput: 551.2 tokens/s, Avg generation throughput: 1529.2 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 57.0%, Prefix cache hit rate: 0.0%
INFO:     127.0.0.1:34344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34172 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34616 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34206 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:20 [loggers.py:118] Engine 000: Avg prompt throughput: 1387.4 tokens/s, Avg generation throughput: 1178.0 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 60.3%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:30 [loggers.py:118] Engine 000: Avg prompt throughput: 1108.8 tokens/s, Avg generation throughput: 1258.2 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 63.0%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:40 [loggers.py:118] Engine 000: Avg prompt throughput: 727.2 tokens/s, Avg generation throughput: 1408.6 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 66.8%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34172 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:46:50 [loggers.py:118] Engine 000: Avg prompt throughput: 928.7 tokens/s, Avg generation throughput: 1298.6 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 70.4%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:00 [loggers.py:118] Engine 000: Avg prompt throughput: 1374.4 tokens/s, Avg generation throughput: 1118.7 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 76.6%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:10 [loggers.py:118] Engine 000: Avg prompt throughput: 1715.9 tokens/s, Avg generation throughput: 957.5 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 76.0%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:20 [loggers.py:118] Engine 000: Avg prompt throughput: 1736.5 tokens/s, Avg generation throughput: 978.3 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 83.0%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:33992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:30 [loggers.py:118] Engine 000: Avg prompt throughput: 847.4 tokens/s, Avg generation throughput: 1199.0 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 86.6%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:40 [loggers.py:118] Engine 000: Avg prompt throughput: 858.5 tokens/s, Avg generation throughput: 1159.0 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 89.6%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:47:50 [loggers.py:118] Engine 000: Avg prompt throughput: 841.4 tokens/s, Avg generation throughput: 1128.4 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 85.2%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:00 [loggers.py:118] Engine 000: Avg prompt throughput: 1331.9 tokens/s, Avg generation throughput: 1018.6 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 87.6%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:33936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34206 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:10 [loggers.py:118] Engine 000: Avg prompt throughput: 423.9 tokens/s, Avg generation throughput: 1209.0 tokens/s, Running: 98 reqs, Waiting: 0 reqs, GPU KV cache usage: 89.0%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:20 [loggers.py:118] Engine 000: Avg prompt throughput: 564.7 tokens/s, Avg generation throughput: 1199.0 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 90.0%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:30 [loggers.py:118] Engine 000: Avg prompt throughput: 900.5 tokens/s, Avg generation throughput: 1058.9 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 94.7%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:40 [loggers.py:118] Engine 000: Avg prompt throughput: 1095.2 tokens/s, Avg generation throughput: 1048.8 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 97.2%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34062 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:48:50 [loggers.py:118] Engine 000: Avg prompt throughput: 812.4 tokens/s, Avg generation throughput: 1039.0 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 96.2%, Prefix cache hit rate: 0.1%
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:00 [loggers.py:118] Engine 000: Avg prompt throughput: 914.3 tokens/s, Avg generation throughput: 1118.3 tokens/s, Running: 99 reqs, Waiting: 1 reqs, GPU KV cache usage: 100.0%, Prefix cache hit rate: 0.7%
INFO:     127.0.0.1:34114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:10 [loggers.py:118] Engine 000: Avg prompt throughput: 420.6 tokens/s, Avg generation throughput: 1181.5 tokens/s, Running: 93 reqs, Waiting: 7 reqs, GPU KV cache usage: 100.0%, Prefix cache hit rate: 9.3%
INFO:     127.0.0.1:34088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:20 [loggers.py:118] Engine 000: Avg prompt throughput: 838.5 tokens/s, Avg generation throughput: 841.8 tokens/s, Running: 91 reqs, Waiting: 8 reqs, GPU KV cache usage: 98.2%, Prefix cache hit rate: 18.1%
INFO:     127.0.0.1:34126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:30 [loggers.py:118] Engine 000: Avg prompt throughput: 566.6 tokens/s, Avg generation throughput: 1095.9 tokens/s, Running: 86 reqs, Waiting: 13 reqs, GPU KV cache usage: 98.5%, Prefix cache hit rate: 24.4%
INFO:     127.0.0.1:34658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34534 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:40 [loggers.py:118] Engine 000: Avg prompt throughput: 357.4 tokens/s, Avg generation throughput: 891.2 tokens/s, Running: 89 reqs, Waiting: 11 reqs, GPU KV cache usage: 99.7%, Prefix cache hit rate: 27.7%
INFO:     127.0.0.1:34142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:49:50 [loggers.py:118] Engine 000: Avg prompt throughput: 631.0 tokens/s, Avg generation throughput: 1034.3 tokens/s, Running: 82 reqs, Waiting: 17 reqs, GPU KV cache usage: 99.6%, Prefix cache hit rate: 31.6%
INFO:     127.0.0.1:34022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:00 [loggers.py:118] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1006.9 tokens/s, Running: 76 reqs, Waiting: 24 reqs, GPU KV cache usage: 99.3%, Prefix cache hit rate: 30.6%
INFO:     127.0.0.1:34050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:10 [loggers.py:118] Engine 000: Avg prompt throughput: 933.8 tokens/s, Avg generation throughput: 647.0 tokens/s, Running: 80 reqs, Waiting: 20 reqs, GPU KV cache usage: 99.8%, Prefix cache hit rate: 31.7%
INFO:     127.0.0.1:34298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:20 [loggers.py:118] Engine 000: Avg prompt throughput: 829.8 tokens/s, Avg generation throughput: 787.0 tokens/s, Running: 86 reqs, Waiting: 14 reqs, GPU KV cache usage: 99.4%, Prefix cache hit rate: 34.7%
INFO:     127.0.0.1:34694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34160 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:30 [loggers.py:118] Engine 000: Avg prompt throughput: 1385.4 tokens/s, Avg generation throughput: 858.3 tokens/s, Running: 94 reqs, Waiting: 6 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 33.8%
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:40 [loggers.py:118] Engine 000: Avg prompt throughput: 469.6 tokens/s, Avg generation throughput: 989.9 tokens/s, Running: 96 reqs, Waiting: 4 reqs, GPU KV cache usage: 100.0%, Prefix cache hit rate: 33.7%
INFO:     127.0.0.1:34212 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:50:50 [loggers.py:118] Engine 000: Avg prompt throughput: 906.3 tokens/s, Avg generation throughput: 978.0 tokens/s, Running: 99 reqs, Waiting: 0 reqs, GPU KV cache usage: 99.0%, Prefix cache hit rate: 33.5%
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34172 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:00 [loggers.py:118] Engine 000: Avg prompt throughput: 434.2 tokens/s, Avg generation throughput: 1134.8 tokens/s, Running: 100 reqs, Waiting: 0 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 33.6%
INFO:     127.0.0.1:34298 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:10 [loggers.py:118] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1134.2 tokens/s, Running: 92 reqs, Waiting: 8 reqs, GPU KV cache usage: 99.8%, Prefix cache hit rate: 34.2%
INFO:     127.0.0.1:34432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34198 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34160 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:20 [loggers.py:118] Engine 000: Avg prompt throughput: 771.3 tokens/s, Avg generation throughput: 950.5 tokens/s, Running: 96 reqs, Waiting: 3 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 33.9%
INFO:     127.0.0.1:34270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34276 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:30 [loggers.py:118] Engine 000: Avg prompt throughput: 313.5 tokens/s, Avg generation throughput: 1134.0 tokens/s, Running: 91 reqs, Waiting: 9 reqs, GPU KV cache usage: 99.0%, Prefix cache hit rate: 32.2%
INFO:     127.0.0.1:34012 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:40 [loggers.py:118] Engine 000: Avg prompt throughput: 479.5 tokens/s, Avg generation throughput: 997.5 tokens/s, Running: 84 reqs, Waiting: 16 reqs, GPU KV cache usage: 98.4%, Prefix cache hit rate: 32.0%
INFO:     127.0.0.1:34346 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34470 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34364 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33992 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:51:50 [loggers.py:118] Engine 000: Avg prompt throughput: 606.8 tokens/s, Avg generation throughput: 838.3 tokens/s, Running: 79 reqs, Waiting: 20 reqs, GPU KV cache usage: 98.5%, Prefix cache hit rate: 31.8%
INFO:     127.0.0.1:34550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:00 [loggers.py:118] Engine 000: Avg prompt throughput: 1222.0 tokens/s, Avg generation throughput: 809.5 tokens/s, Running: 86 reqs, Waiting: 14 reqs, GPU KV cache usage: 99.9%, Prefix cache hit rate: 31.6%
INFO:     127.0.0.1:33900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34206 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:10 [loggers.py:118] Engine 000: Avg prompt throughput: 576.9 tokens/s, Avg generation throughput: 928.0 tokens/s, Running: 84 reqs, Waiting: 15 reqs, GPU KV cache usage: 98.6%, Prefix cache hit rate: 31.5%
INFO:     127.0.0.1:34366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34448 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:20 [loggers.py:118] Engine 000: Avg prompt throughput: 953.0 tokens/s, Avg generation throughput: 923.1 tokens/s, Running: 86 reqs, Waiting: 14 reqs, GPU KV cache usage: 99.5%, Prefix cache hit rate: 31.4%
INFO:     127.0.0.1:34644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34556 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:30 [loggers.py:118] Engine 000: Avg prompt throughput: 788.7 tokens/s, Avg generation throughput: 920.1 tokens/s, Running: 83 reqs, Waiting: 16 reqs, GPU KV cache usage: 96.1%, Prefix cache hit rate: 33.0%
INFO:     127.0.0.1:34630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34640 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:33982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:40 [loggers.py:118] Engine 000: Avg prompt throughput: 1708.1 tokens/s, Avg generation throughput: 655.0 tokens/s, Running: 86 reqs, Waiting: 14 reqs, GPU KV cache usage: 97.5%, Prefix cache hit rate: 32.7%
INFO:     127.0.0.1:34306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34578 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:34440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 07-04 09:52:50 [loggers.py:118] Engine 000: Avg prompt throughput: 570.9 tokens/s, Avg generation throughput: 935.2 tokens/s, Running: 87 reqs, Waiting: 13 reqs, GPU KV cache usage: 99.6%, Prefix cache hit rate: 34.9%
INFO:     127.0.0.1:34036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
